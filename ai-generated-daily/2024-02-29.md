1.Llama-2上下文扩展至128k，10倍吞吐量仅需1/6内存

陈丹琦团队刚刚发布了一种新的LLM上下文窗口扩展方法：

它仅用8k大小的token文档进行训练，就能将Llama-2窗口扩展至128k。

最重要的是，在这个过程中，只需要原来1/6的内存，模型就获得了10倍吞吐量。

这个方法名叫CEPE，全称“并行编码上下文扩展（Context Expansion with Parallel Encoding）”。

作为轻量级框架，它可用于扩展任何预训练和指令微调模型的上下文窗口。

对于任何预训练的仅解码器语言模型，CEPE通过添加两个小组件来实现扩展：

一个是小型编码器，用于对长上下文进行块编码；

一个是交叉注意力模块，插入到解码器的每一层，用于关注编码器表示。

https://arxiv.org/abs/2402.16617

2.LLaMa 3或将推迟到7月发布，剑指GPT-4，从Gemini吸取教训

过去的图像生成模型常被人们诟病人物主要以「白人」为主，而谷歌 Gemini 正在因为它的矫枉过正而深陷翻车风波。

它「过度谨慎」的文生图结果会与历史事实出现极大偏差，让用户们瞠目结舌。

谷歌表示，该模型变得比开发者预期的更加谨慎。

这不仅体现在生成图片的问题上，还体现在常常将一些提示认作敏感提示，从而拒绝回答。

https://www.reuters.com/technology/meta-plans-launch-new-ai-language-model-llama-3-july-information-reports-2024-02-28/


3.Morph Studio 可让您使用 Stability AI 生成的剪辑来制作电影

工作流程制作电影

https://app.morphstudio.com/waitlist

4.Adobe AI 音乐原型工具

https://www.theverge.com/2024/2/28/24085551/adobe-project-music-genai-control-prototype-tool-hot-pod

5.Figure: 数十亿台机器人推向世界

Figure 目标是创造价格实惠且实用的人形机器人。

https://mp.weixin.qq.com/s/QmHLXCcNVIQsFKqX47bidw

6.Mistral 仍然致力开发重量模型

https://x.com/arthurmensch/status/1762818733016322168?s=20

7.StarCoder2:一系列新一年开发源代码大模型

写代码大模型

https://x.com/osanseviero/status/1762845923636318649?s=20


