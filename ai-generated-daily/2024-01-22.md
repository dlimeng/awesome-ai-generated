1.Yann LeCun：生成模型不适合处理视频，AI得在抽象空间中进行预测

在 2024 世界经济论坛的一次会谈中，图灵奖得主、Meta 首席 AI 科学家 Yann LeCun 被问到了这个问题。他认为，虽然这个问题还没有明确的答案，但适合用来处理视频的模型并不是我们现在大范围应用的生成模型。而且新的模型应该学会在抽象的表征空间中预测，而不是在像素空间中。

一起参与讨论的还有斯坦福大学教授、Coursera 联合创始人 Daphne Koller。她的研究领域主要是人工智能及其在生物医学科学中的应用。她指出了理解因果关系对于构建未来AI系统的重要性。

https://www.weforum.org/events/world-economic-forum-annual-meeting-2024/sessions/the-expanding-universe-of-generative-models/


2.无需训练实现价值观实时动态对齐：上交开源价值观对齐方法OPO，闭源与开源大模型均适用

相比于之前工作中的对齐方法（i.e., SFT、PPO 和 DPO），OPO 方法有如下优势：

无需训练即可实现价值观对齐；

舍弃奖励模型，并对任意大模型均适用，包括开源与闭源大模型；

容易更新待对齐的价值观。考虑到价值观可能会随着时间发生变化（比如法律），OPO 能方便快捷地通过替换相应的准则完成价值观的更新，而其他对齐方法则需要收集数据重新训练模型。

目前，该项目开源了大量资源，包括：

OPO 代码（使用方法和测试流程也已经在 GitHub 上给出）；

5 种类型的测试数据集，包括人出的法考题目、《道德与法治》考试题目（只保留了道德相关的题目）和从 NormBank 数据的测试集中随机采样的题目，以及利用大模型自动生成的法律题目和职业道德题目；

2 大类价值观准则，分别是法律准则和道德准则。法律准则包括截止到 2023 年 7 月中国现行有效的所有法律法规（约 95 万条）。道德准则：①从中学的《道德与法治》教材里收集的基础道德准则；②从网上收集多家不同公司 / 行业的职业道德准则；③从 NormBank 训练集数据中随机抽取得到的社会道德规则；

用于自动生成测试数据的 prompt 以及评估生成的测试数据质量的 prompt；

用 OpenAI embedding 模型提取的法律和道德准则文本对应的向量。

论文地址：https://arxiv.org/abs/2312.15907

项目地址：https://gair-nlp.github.io/OPO/

代码地址：https://github.com/GAIR-NLP/OPO


3.Raschka分享从《零开始的LoRA》: 一种从头开始构建LoRA的实用方法

在LLMs的各种有效微调方法中，LoRA 仍然是我的首选。我刚刚在这里开发并分享了一个“LoRA From Scratch”实现.

这是一种从头开始构建 LoRA 的实践方法，在我看来，这是一种很好的学习方式。

https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?view=public&section=all

4.ML论文排行榜，提供论文摘要和链接

https://github.com/dair-ai/ML-Papers-of-the-Week

5.Taipy 是一款基于Python的UI框架

https://github.com/Avaiga/taipy

6.从GPT-5是什么说起

“目前的GPT-4有太多缺点，比我们今年将拥有的版本要差很多（much worse），比我们明年将拥有的差得更多”
“假如GPT-4目前只能解决人类任务的10%，GPT-5应该是15%或者20%”

https://mp.weixin.qq.com/s/1uKg8QulI7AmWLqS9Q8toA

7.Phil Wang GitHub技术项目集锦

https://github.com/lucidrains?utm_source=wechat_session

