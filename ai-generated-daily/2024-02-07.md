1.无需RLHF显著提升GPT-4/Llama2性能，北大团队提出Aligner对齐新范式

大语言模型（LLMs）虽展现出了强大的能力，但也可能产生不可预测和有害的输出，例如冒犯性回应、虚假信息和泄露隐私数据，给用户和社会造成伤害。确保这些模型的行为与人类意图和价值观相对齐，是一个紧迫的挑战。

尽管基于人类反馈的强化学习（RLHF）提供了一种解决方案，但它面临复杂的训练架构、对参数的高敏感性，以及奖励模型在不同数据集上的不稳定性等多重挑战。这些因素导致 RLHF 技术实现难、奏效难、复现难。

为了克服这些挑战，北京大学团队提出了一种新的高效对齐范式 ——Aligner，其核心在于学习答案对齐与未对齐之间的修正残差，从而绕过繁琐的 RLHF 流程。

论文地址：https://arxiv.org/abs/2402.02416

项目主页 & 开源地址：https://aligner2024.github.io

2.OpenAI提出meta-prompting，最强零样本prompting技术诞生

最新一代语言模型（尤其是 GPT-4、PaLM 和 LLaMa）已经成功拓展了自然语言处理和生成的边界。这些大规模模型可以解决许多不同任务，从写莎士比亚风格的十四行诗到总结复杂的医疗报告和解决竞赛级的编程问题。尽管这些模型可以解决多种多样的问题，但它们并非总是正确的，有时候也会生成不准确、误导性或矛盾的响应结果。

论文地址：https://arxiv.org/abs/2401.12954

项目地址：https://github.com/suzgunmirac/meta-prompting

3.文本生成音频

前几日，在论文《Masked Audio Generation using a Single Non-Autoregressive Transformer》中，Meta FAIR 团队、Kyutai 和希伯来大学推出了 MAGNeT，一种在掩码生成序列建模方法，可以直接在多个音频 tokens 流上直接运行。与以往工作最大的不同是，MAGNeT 是由单阶段、非自回归 transformer 生成音频。

论文地址：https://arxiv.org/pdf/2401.04577.pdf

GitHub 地址：https://github.com/facebookresearch/audiocraft/blob/main/docs/MAGNET.md

4.基于开源小模型的三个Agent协作，比肩GPT-4的工具调用效果！

https://arxiv.org/abs/2401.07324

https://github.com/X-PLUG/Multi-LLM-agent

5.Roblox 构建了一个实时 AI 翻译模型以打造跨语言游戏社区，未来还将探索游戏 3D 素材制作......

https://mp.weixin.qq.com/s/nYKrUkvpsgJu9XpcpS1cKg

6.MetaVoice 1B:12亿参数模型，基于10万小时的数据训练，支持零样本声音克隆

https://twitter.com/reach_vb/status/1754984949654904988?s=20

https://huggingface.co/metavoiceio/metavoice-1B-v0.1

7.由BRIA.AI开发的背景去除模型，在精心挑选的数据集上进行训练，并作为非商业用途的开源模型提供。

https://huggingface.co/spaces/briaai/BRIA-RMBG-1.4

8.Qwen1.5更新细节：解决的一些问题

昨天我们发布了Qwen1.5，也许有一天我会详细分享这次的经验。虽然它还没达到业界顶尖水平，但已经是个不错的版本了。毕竟，顶尖水平的并不多。这次，我们解决了许多问题：

1.所有大小的上下文长度终于统一了。之前，很多用户反映14B只支持2K，即使是动态NTK也表现不佳，只能扩展到4-5K左右。更别提那些不知道如何使用动态NTK的用户了。

2.如果你仔细使用我们的基础语言模型，你会发现它们能理解ChatML的特殊标记，这意味着你可以直接使用LoRA在ChatML格式的数据上进行训练。为什么之前做不到呢？因为如果基础语言模型不理解特殊标记，你就需要对它们进行训练，这意味着你需要开启嵌入训练。这很麻烦，而且在使用ZeRO3时经常会导致问题。

3.我们加强了除72以外的基础语言模型。你应该能找到更好的基础语言模型，特别是7和14。为什么72不行？嗯，很难说，但我们会让它变得更好。

4.关于多语言能力。是的，我们终于建立了多语言评估系统，并发现我们的新基础语言模型在多语言评估中表现不错。这告诉我们应该更加关注使用多语言数据进行后续训练。我们也这么做了。这就是为什么这次我们要谈谈多语言性能。毫无疑问，它比这次发布之前的模型要好得多。

5.聊天模型是最有前景的东西。在这次发布之前，我们给你提供了SFT模型。但这次，我们有了非常不错的SFT+DPO模型。是的，不仅注释者喜欢它们，用户也喜欢它们。我相信你们开发者也会有同样的感觉。

https://huggingface.co/posts/JustinLin610/764363519759697