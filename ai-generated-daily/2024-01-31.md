1.26个SOTA模型

近日，腾讯 AI Lab、京都大学和穆罕默德・本・扎耶德人工智能大学的一个研究团队发布了一份综述报告，全面梳理了 MM-LLM 的近期进展。文中不仅总结了 MM-LLM 的模型架构和训练流程，而且还梳理了 26 个当前最佳的 MM-LLM。如果你正考虑研究或使用 MM-LLM，不妨考虑从这份报告开始研究，找到最符合你需求的模型。

论文地址：https://arxiv.org/abs/2401.13601

2.Mistral-Medium意外泄露?

泄露传闻与一个名为「Miqu」的新模型有关，在评估语言模型情商的基准 EQ-Bench（EQ-Bench 与 MMLU 的相关性约为 0.97、与 Arena Elo 的相关性约为 0.94）上， Miqu 直接吊打了除 GPT-4 之外的所有大模型，而且它的得分与 Mistral-Medium 非常接近

开源地址：https://huggingface.co/miqudev/miqu-1-70b


3.GLM-4 模型开放API 正式上线

基础能力（英文）：GLM-4 在 MMLU、GSM8K、MATH、BBH、HellaSwag、HumanEval等数据集上，分别达到GPT-4 94%、95%、91%、99%、90%、100%的水平。


指令跟随能力：GLM-4在IFEval的prompt级别上中、英分别达到GPT-4的88%、85%的水平，在Instruction级别上中、英分别达到GPT-4的90%、89%的水平。


对齐能力：GLM-4在中文对齐能力上整体超过GPT-4。


长文本能力：我们在LongBench（128K）测试集上对多个模型进行评测，GLM-4性能超过 Claude 2.1；在「大海捞针」（128K）实验中，GLM-4的测试结果为 128K以内全绿，做到100%精准召回。


多模态-文生图：CogView3在文生图多个评测指标上，相比DALLE3 约在 91.4% ~99.3%的水平之间。

https://mp.weixin.qq.com/s/KF2s7Tdi2YIrjWMBwB1Vyg

4.2023年投融资报告：414家中国企业完成IPO，同比下降19%；深创投收获22个IPO；中金资本、英伟达捕获最多新晋独角兽

https://mp.weixin.qq.com/s/yzOnAuscdCEwQ9QdRHQpQg


