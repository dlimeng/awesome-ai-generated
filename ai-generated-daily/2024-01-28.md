1.Llama-2+Mistral+MPT=? 融合多个异构大模型显奇效

随着 LLaMA、Mistral 等大语言模型的成功，各家大厂和初创公司都纷纷创建自己的大语言模型。但从头训练新的大语言模型所需要的成本十分高昂，且新旧模型之间可能存在能力的冗余。

近日，中山大学和腾讯 AI Lab 的研究人员提出了 FuseLLM，用于「融合多个异构大模型」。

不同于以往的模型集成和权重合并，前者需要在推理时同时部署多个大语言模型，后者需要合并模型具备相同的结果，FuseLLM 能够从多个异构大语言模型中外化知识，将各自的知识和能力通过轻量的持续训练转移到一个融合大语言模型中。

论文标题：Knowledge Fusion of Large Language Models

论文地址：https://arxiv.org/abs/2401.10491

论文仓库：https://github.com/fanqiwan/FuseLLM

2.重塑3D生成核心理论：VAST、港大、清华用「零」训练数据生成了3D模型

论文地址：https://arxiv.org/abs/2310.19415

项目地址：https://xinyu-andy.github.io/Classifier-Score-Distillation

代码地址：https://github.com/CVMI-Lab/Classifier-Score-Distillation

论文标题：Text-to-3D with Classifier Score Distillation

3.马斯克还表示，特斯拉计划在2024年底之前投资超过10亿美元，用于一个名为“Dojo”的项目。Dojo指的是一台内部超级计算机，旨在处理大量数据，包括创建自动驾驶软件所需的来自特斯拉汽车的视频。

“如果没有约25%的投票控制权，我不愿意把特斯拉发展成为人工智能和机器人领域的领导者。”

4.InstructGPT 两周年，现代所有LLM之母

https://twitter.com/DrJimFan/status/1751285761364906476?s=20

https://openai.com/research/instruction-following

5.Lumos 

https://github.com/andrewnguonly/Lumos 

Lumos是一个开源项目,它提供了一个AI助手来帮助用户浏览网页。

Lumos的核心是基于RAG(检索增强生成)结构的LLM(大语言模型),可以查询知识库并生成回复。

